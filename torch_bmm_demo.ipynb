{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.bmm() 与 torch.matmul()\n",
    "\n",
    "- torch.bmm()强制规定维度和大小相同\n",
    "- torch.matmul()没有强制规定维度和大小，可以用利用广播机制进行不同维度的相乘操作\n",
    "- 当进行操作的两个tensor都是3D时，两者等同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.bmm()\n",
    "\n",
    "torch.bmm(input, mat2, *, deterministic=False, out=None)\n",
    "\n",
    "Performs a batch matrix-matrix product of matrices stored in input and mat2.\n",
    "input and mat2 must be 3-D tensors each containing the same number of matrices.\n",
    "\n",
    "This function does not broadcast. For broadcasting matrix products, see torch.matmul()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input = torch.randn(10, 3, 4)\n",
    "mat2 = torch.randn(10, 4, 5)\n",
    "res = torch.bmm(input, mat2)\n",
    "print(res.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当tensor维度为2时会报错！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=torch.randn((2,5))\n",
    "print(c)\n",
    "\n",
    "d=torch.reshape(c,(5,2))\n",
    "print(d)\n",
    "tensor([[ 1.0559, -0.3533],\n",
    "        [ 0.5194,  0.9526],\n",
    "        [-0.2483, -0.1293],\n",
    "        [ 0.4809, -0.5268],\n",
    "        [-0.3673,  0.0666]])\n",
    ">>> e=torch.bmm(c,d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "维度为4时也会报错！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc=torch.randn((1,2,2,5))\n",
    "ddd=torch.randn((1,2,5,2))\n",
    "e=torch.bmm(ccc,ddd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.matmul()\n",
    "\n",
    " torch.matmul()也是一种类似于矩阵相乘操作的tensor联乘操作。但是它可以利用python 中的广播机制，处理一些维度不同的tensor结构进行相乘操作。这也是该函数与torch.bmm()区别所在。\n",
    "\n",
    "参数：\n",
    "\n",
    "input,other：两个要进行操作的tensor结构\n",
    "\n",
    "output:结果\n",
    "\n",
    "一些规则约定：\n",
    "\n",
    "（1）若两个都是1D（向量）的，则返回两个向量的点积\n",
    "————————————————\n",
    "版权声明：本文为CSDN博主「Foneone」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\n",
    "原文链接：https://blog.csdn.net/foneone/article/details/103876519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.rand(2)\n",
    "y = torch.rand(2)\n",
    "print(torch.matmul(x,y),torch.matmul(x,y).size())\n",
    "output：\n",
    "tensor(0.1353) torch.Size([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2）若两个都是2D（矩阵）的，则按照（矩阵相乘）规则返回2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2,4)\n",
    "y = torch.rand(4,3) ###维度也要对应才可以乘\n",
    "print(torch.matmul(x,y),'\\n',torch.matmul(x,y).size())\n",
    " \n",
    "output:\n",
    "tensor([[0.9128, 0.8425, 0.7269],\n",
    "        [1.4441, 1.5334, 1.3273]]) \n",
    " torch.Size([2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若input维度1D，other维度2D，则先将1D的维度扩充到2D（1D的维数前面+1），然后得到结果后再将此维度去掉，得到的与input的维度相同。即使作扩充（广播）处理，input的维度也要和other维度做对应关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.rand(4) #1D\n",
    "y = torch.rand(4,3) #2D\n",
    "print(x.size())\n",
    "print(y.size())\n",
    "print(torch.matmul(x,y),'\\n',torch.matmul(x,y).size())\n",
    " \n",
    "### 扩充x =>(,4) \n",
    "### 相乘x(,4) * y(4,3) =>(,3) \n",
    "### 去掉1D =>(3)\n",
    " \n",
    "output:\n",
    "torch.Size([4])\n",
    "torch.Size([4, 3])\n",
    "tensor([0.9600, 0.5736, 1.0430]) \n",
    " torch.Size([3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（4）若input是2D，other是1D，则返回两者的点积结果。（个人觉得这块也可以理解成给other添加了维度，然后再去掉此维度，只不过维度是(3, )而不是规则(3)中的( ,4)了，但是可能就是因为内部机制不同，所以官方说的是点积而不是维度的升高和下降）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.rand(3) #1D\n",
    "y = torch.rand(4,3) #2D\n",
    "print(torch.matmul(y,x),'\\n',torch.matmul(y,x).size()) #2D*1D\n",
    " \n",
    "output:\n",
    "torch.Size([3])\n",
    "torch.Size([4, 3])\n",
    "tensor([0.8278, 0.5970, 1.0370, 0.2681]) \n",
    " torch.Size([4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
